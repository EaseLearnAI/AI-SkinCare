Windows
设置临时环境变量
设置永久环境变量



如果您希望 API Key 环境变量在当前用户的所有新会话中生效，可以添加永久性环境变量。

在 CMD 中
您可以使用setx命令为当前用户设置永久性环境变量。

打开 CMD ，输入以下命令，其中将<ARK_API_KEY>替换为您的方舟 API Key。

setx ARK_API_KEY "<ARK_API_KEY>"
验证环境变量是否设置成功，在新打开 CMD 窗口中，输入以下命令，如果返回您的 API Key，则表示设置成功。

echo %ARK_API_KEY%

在 PowerShell 中
您可以使用以下命令为当前用户设置永久性环境变量。

打开 PowerShell ，输入以下命令，其中将<ARK_API_KEY>替换为您的方舟 API Key。

[Environment]::SetEnvironmentVariable("ARK_API_KEY", "<ARK_API_KEY>", [EnvironmentVariableTarget]::User)
验证环境变量是否设置成功，在新打开PowerShell窗口中，输入以下命令，如果返回您的 API Key，则表示设置成功。

$env:ARK_API_KEY


 
 
2. 请参考如下示例代码进行调用
import os
from openai import OpenAI

# 请确保您已将 API Key 存储在环境变量 ARK_API_KEY 中
# 初始化Ark客户端，从环境变量中读取您的API Key
client = OpenAI(
    # 此为默认路径，您可根据业务所在地域进行配置
    base_url="https://ark.cn-beijing.volces.com/api/v3",
    # 从环境变量中获取您的 API Key。此为默认方式，您可根据需要进行修改
    api_key=os.environ.get("ARK_API_KEY"),
)

response = client.chat.completions.create(
    # 指定您创建的方舟推理接入点 ID，此处已帮您修改为您的推理接入点 ID
    model="ep-20250326232808-brg8k",
    messages=[
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "这是哪里？"},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": "https://ark-project.tos-cn-beijing.volces.com/images/view.jpeg"
                    },
                },
            ],
        }
    ],
)

print(response.choices[0])

#模型调用接口文档

POST https://ark.cn-beijing.volces.com/api/v3/chat/completions
本文介绍Doubao多模态大模型API的输入输出参数，方便您调用接口ChatCompletions，向大模型发起视觉理解的请求。模型会依据传入的图片信息以及问题，给出回复。

如了解如何调用API进行图片/视频理解，查看示例代码，请查阅教程视觉理解。


调试
API Explorer
您可以通过 API Explorer 在线发起调用，无需关注签名生成过程，快速获取调用结果。
去调试

鉴权方式
本接口支持 API Key 鉴权方式，详见鉴权认证方式。

如果您需要使用Access Key来调用，可以使用接口来获取临时API Key，详细接口说明请参见GetApiKey - 获取临时API 。


使用限制
图片文件大小、尺寸、数量等详细使用限制和规格请参见使用说明。

请求参数

请求体
参数名称

类型

是否必填

默认值

描述

示例值

model

String

是

-

本次请求使用模型的 Model ID，或者使用已配置的视觉理解模型的推理接入点 (Endpoint ID)。

如无推理接入点，请参考创建推理接入点文档创建。
Model ID查询请访问模型列表。

doubao-1.5-vision-pro-32k-250115
或
ep-202406040*****-*****

messages

Array of MessageParam

是

-

由目前为止的对话组成的消息列表，包含用户输入的最后一条消息。

-

stream

Boolean

否

false

响应内容是否流式返回

false：模型生成完所有内容后一次性返回结果
true：按 SSE 协议逐块返回模型生成内容，并以一条 data: [DONE] 消息结束
false

stream_options

Object ofStreamOptionsParam

否

-

流式响应的选项。仅当 stream: true 时可以设置 stream_options 参数。

-

extra_headers

Object

否

-

用于传递自定义请求头，覆盖默认请求头，字段的格式如下：
{"key1": "value1","key2": "value2",..,"keyN": "valueN"}
取值范围：

{'x-is-encrypted': 'true'}：开启推理会话应用层加密。具体使用示例请参考对话加密。
-

max_tokens

Integer

否

4096

注意

模型回复最大长度（单位 token），取值范围各个模型不同，详细见模型列表。
输入 token 和输出 token 的总长度还受模型的上下文长度限制。
4096

service_tier

string

否

auto

指定是否使用TPM保障包。生效对象为购买了保障包推理接入点。取值范围

auto：默认为auto，即优先使用TPM保障包。如果购买了TPM保障包，且有TPM保障包额度的推理接入点，本次请求将会使用TPM保障包用量，获得更高限流以及响应速度。否则不使用，使用默认的限流，和普通的服务响应速度。
default：本次请求，不使用 TPM 保障包，使用默认的限流和普通的服务响应速度，即使请求的是有TPM保障包额度的推理接入点。
auto

stop

String or Array

否

-

模型遇到 stop 字段所指定的字符串时将停止继续生成，这个词语本身不会输出。最多支持 4 个字符串。

["你好", "天气"]

temperature

Float

否

1

采样温度。控制了生成文本时对每个候选词的概率分布进行平滑的程度。取值范围为 [0, 1]。
较高的值（如 0.8）会使输出更加随机，而较低的值（如 0.2）会使输出更加集中确定。
通常建议仅调整 temperature 或 top_p 其中之一，不建议两者都修改。

0.8

top_p

Float

否

0.7

核采样概率阈值。模型会考虑概率质量在 top_p 内的 token 结果。取值范围为 [0, 1]，取值越大生成的随机性越高，取值越低生成的确定性越高。
举例来说，当取值为 0.1 时，模型仅考虑按照概率大小排序前列（token按照概率由大到小排序，累加概率达到阈值10%，即top_p=0.1）的 token，随机取一个作为输出。
通常建议仅调整 temperature 或 top_p 其中之一，不建议两者都修改。

0.8

logprobs

Boolean

否

false

是否返回输出 token 的对数概率。

false：不返回对数概率信息。
true：返回消息内容中每个输出 token 的对数概率。
false

top_logprobs

Integer

否

0

指定每个输出 token 位置最有可能返回的 token 数量，每个 token 都有关联的对数概率。仅当 logprobs: true 时可以设置 top_logprobs 参数，取值范围为 [0, 20]。

2

logit_bias

Map<String, Integer>

否

-

调整指定 token 在模型输出内容中出现的概率，使模型生成的内容更加符合特定的偏好。logit_bias 字段接受一个 map 值，其中每个键为词表中的 token ID（使用 tokenization 接口获取），每个值为该 token 的偏差值，取值范围为 [-100, 100]。
-1 会减少选择的可能性，1 会增加选择的可能性；-100 会完全禁止选择该 token，100 会导致仅可选择该 token。该参数的实际效果可能因模型而异。

{
    "1234": -100
}
-


数据结构

MessageParam

系统消息
参数名称

子字段

类型

是否必填

描述

role

String

是

发出该消息的对话参与者的角色，此处应设置为 system 。

content

-

Array

是

视觉理解模型请求的消息内容，消息发送角色为system。

type

String

是

text 或 image_url，传入的信息类型。
传入信息为文本信息设置为text。
传入信息为图片信息设置为image_url。
text

String

条件必填

当type设置为text时，输入文本信息。
[
    {
      "role": "system",
      "content": [
        {
          "type": "text",
          "text": "你叫什么"
        }
      ]
    }
  ]
image_url

Object

是

图片信息。

url[String]：必选，支持传入图片链接或图片的Base64编码，不同模型支持图片大小略有不同，具体请参见使用说明。
传入图片URL。
传入Base64编码：请遵循格式data:image/<图片格式>;base64,<Base64编码>，完整示例请参见Base64编码输入。
<图片格式>：图片的格式
<Base64编码>：图片的Base64编码。
detail[String]：可选，支持手动设置图片的质量，取值范围high、low、auto。
high：高细节模式，适用于需要理解图像细节信息的场景，如对图像的多个局部信息/特征提取、复杂/丰富细节的图像理解等场景，理解更全面。
low：低细节模式，适用于简单的图像分类/识别、整体内容理解/描述等场景，理解更快速。
auto：默认模式，不同模型选择的模式略有不同，具体请参见理解图像的深度控制。
更多配置建议，请参见使用说明。


用户消息
参数名称

子字段

类型

是否必填

描述

role

String

是

发出该消息的对话参与者的角色，此处应设置为 user 。

content

-

Array

是

视觉理解模型请求的消息内容，消息发送角色为用户。

示例：多图像输入
示例： Base64 编码输入
type

String

是

text 或 image_url，传入的信息类型。
传入信息为文本信息设置为text。
传入信息为图片信息设置为image_url。
text

String

条件必填

当type设置为text时，输入文本信息。
[
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "你叫什么"
        }
      ]
    }
  ]
image_url

Object

是

图片信息。

url[String]：必选，支持传入图片链接或图片的Base64编码，不同模型支持图片大小略有不同，具体请参见使用说明。
传入图片URL。
传入Base64编码：请遵循格式data:image/<图片格式>;base64,<Base64编码>，完整示例请参见Base64编码输入。
<图片格式>：图片的格式
<Base64编码>：图片的Base64编码。
detail[String]：可选，支持手动设置图片的质量，取值范围high、low、auto。
high：高细节模式，适用于需要理解图像细节信息的场景，如对图像的多个局部信息/特征提取、复杂/丰富细节的图像理解等场景，理解更全面。
low：低细节模式，适用于简单的图像分类/识别、整体内容理解/描述等场景，理解更快速。
auto：默认模式，不同模型选择的模式略有不同，具体请参见理解图像的深度控制。
更多配置建议，请参见使用说明。


模型消息
参数名称

类型

是否必填

描述

role

String

是

发出该消息的对话参与者的角色，此处应设置为 assistant。

content

String

是

模型的消息回复。

[
  {
    "role": "assistant",
    "content": "Hello, can i help you with something?"
  }
]

StreamOptionsParam
参数名称

类型

是否必填

默认值

描述

示例值

include_usage

Boolean

否

false

是否包含本次请求的 token 用量统计信息

false：不返回 token 用量信息
true：在 data: [DONE] 消息之前返回一个额外的块，此块上的 usage 字段代表整个请求的 token 用量，choices 字段为空数组。所有其他块也将包含 usage 字段，但值为 null。
false


响应参数

非流式调用
参数名称

子字段

类型

描述

id

-

String

一次 chat completion 接口调用的唯一标识。

choices

-

Array

本次 chat 结果列表。长度固定为 1。

index

Integer

该元素在 choices 列表的索引。

message

Object

模型输出的消息内容。

finish_reason

String

模型生成结束原因：

stop：正常生成结束。
length 触发最大 token 数量而结束。
content_filter ：模型输出被内容审核拦截。
logprobs

Object

该输出结果的概率信息，其只有一个 content 字段，类型为 Array，表示 message 列表中每个元素 content token 的概率信息。
content 元素子字段说明如下：

token [String]: 对应 token。
logprob [Number]：token 的概率。
bytes [Array]：表示 token 的 UTF-8 字节表示的整数列表。在字符由多个 token 表示，并且它们的字节表示必须组合以生成正确的文本表示的情况下（表情符号或特殊字符）非常有用。如果 token 没有 byte 表示，则可以为空。
top_logprobs [Array]：最可能的 token 列表及其在此 token 位置的对数概率：
token [String]: 对应 token；
logprob [Number]：token 的概率；
bytes [Array]：表示 token 的 UTF-8 字节表示的整数列表。在字符由多个 token 表示，并且它们的字节表示必须组合以生成正确的文本表示的情况下（表情符号或特殊字符）非常有用。如果 token 没有 byte 表示，则可以为空。
moderation_hit_type

String

模型输出文字含有敏感信息时，会返回该字段，表示模型输出文字命中的风险分类标签。
当前返回值的取值范围：

severe_violation：模型输出文字涉及严重违规
violence：模型输出文字涉及激进行为
注意：只有在方舟控制台接入点配置页面或者 CreateEndpoint 接口中，将内容护栏方案（ModerationStrategy）设置为基础方案（Basic）时，才会返回风险分类标签。

created

-

Integer

本次对话生成的时间戳（秒）。

model

-

String

实际使用的模型名称和版本。

Doubao 1.5 代模型的模型名称格式为 doubao-1-5-**，如调用部署doubao-1.5-pro-32k 250115模型的推理接入点，返回model字段信息doubao-1-5-pro-32k-250115。

service_tier

-

String

本次请求是否使用了TPM保障包。

scale：本次请求使用TPM保障包额度。
default：本次请求未使用TPM保障包额度。
object

-

String

固定为 chat.completion。

usage

-

Object

本次请求的 token 用量。

prompt_tokens

Integer

本次请求中输入的 token 数量。

completion_tokens

Integer

模型生成的 token 数量。

total_tokens

Integer

总的 token 数量。

prompt_tokens_details

Object

本接口暂不支持上下文缓存，此时返回应为"cached_tokens": 0。

prompt_tokens中命中上下文缓存的tokens数。需要模型支持，且开通上下文缓存功能，并创建缓存才会启用，详细见上下文缓存（Context API）概述。

"prompt_tokens_details": {
    "cached_tokens": 0
    }

流式调用
字段

子字段

类型

描述

id

-

String

一次 chat completion 接口调用的唯一标识，一次流式调用所有的 chunk 有相同的 id。

choices

-

Array

结果列表。长度固定为 1。如果设置了stream_options: {"include_usage": true}，则最后一个 chunk 的 choices 也为空列表。

index

Integer

该元素在 choices 列表的索引。

delta

Object

由流式模型响应的模型输出增量，示例如下。

{
  "role": "assistant",
  "content": " there"
}
finish_reason

String

模型生成结束原因，stop表示正常生成结束，length 表示已经到了生成的最大 token 数量，content_filter 表示模型输出命中审核提前终止。

logprobs

Object

该输出结果的概率信息，其只有一个 content 字段，类型为 array，表示 message 列表中每个元素 content token 的概率信息，content 元素子字段说明如下：

token [String]: 对应 token；
logprob [Number]：token 的概率；
bytes [Array]：表示 token 的 UTF-8 字节表示的整数列表。在字符由多个 token 表示，并且它们的字节表示必须组合以生成正确的文本表示的情况下（表情符号或特殊字符）非常有用。如果 token 没有 byte 表示，则可以为空。
top_logprobs [Array]：最可能的 token 列表及其在此 token 位置的对数概率：
token [String]: 对应 token；
logprob [Number]：token 的概率；
bytes [Array]：表示 token 的 UTF-8 字节表示的整数列表。在字符由多个 token 表示，并且它们的字节表示必须组合以生成正确的文本表示的情况下（表情符号或特殊字符）非常有用。如果 token 没有 byte 表示，则可以为空。
moderation_hit_type

String

模型输出文字含有敏感信息时，会返回该字段，表示模型输出文字命中的风险分类标签。
当前返回值的取值范围：

severe_violation：模型输出文字涉及严重违规
violence：模型输出文字涉及激进行为
注意：只有在方舟控制台接入点配置页面或者 CreateEndpoint 接口中，将内容护栏方案（ModerationStrategy）设置为基础方案（Basic）时，才会返回风险分类标签。

created

-

Integer

本次对话生成时间戳（秒）。

model

-

String

实际使用的模型名称和版本。

Doubao 1.5 代模型的模型名称格式为 doubao-1-5-**，如调用部署doubao-1.5-pro-32k 250115模型的推理接入点，返回model字段信息doubao-1-5-pro-32k-250115。

service_tier

-

String

本次请求是否使用了TPM保障包。

scale：本次请求使用TPM保障包额度。
default：本次请求未使用TPM保障包额度。
object

-

String

固定为 chat.completion.chunk。

usage

-

Object

本次请求的 token 用量。
一个可选字段，仅当在请求中设置stream_options: {"include_usage": true}时才会出现。如果设置了它，除了最后一个 chunk 包含整个请求的 token 使用量外，其它 chunk 的 usage 都是 null。

prompt_tokens

Integer

本次请求中输入的 token 数量。

completion_tokens

Integer

模型生成的 token 数量。

total_tokens

Integer

总的 token 数量。

prompt_tokens_details

Object

本接口暂不支持上下文缓存，此时返回应为"cached_tokens": 0。

prompt_tokens中命中上下文缓存的tokens数。需要模型支持，且开通上下文缓存功能，并创建缓存才会启用，详细见上下文缓存（Context API）概述。

"prompt_tokens_details": {
    "cached_tokens": 0
}

请求示例
curl https://ark.cn-beijing.volces.com/api/v3/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer 59385462-****" \
  -d '{
        "model": "doubao-1.5-vision-pro-32k-250115",
        "messages": [
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "图片主要讲了什么?"
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": "https://ark-project.tos-cn-beijing.volces.com/doc_image/ark_demo_img_1.png"
                        }
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": "https://ark-project.tos-cn-beijing.volces.com/doc_image/ark_demo_img_2.png"
                        }
                    }
                ]
            }
        ]
    }'

响应示例
{
    "choices": [
        {
            "finish_reason": "stop",
            "index": 0,
            "logprobs": null,
            "message": {
                "content": "这张图片由两部分组成。\n\n左侧的图片展示了一幅宁静的自然景观。画面中央是一片平静的湖水，湖面上有一艘橙色的皮划艇，艇上有一个人正在划船。湖的对岸是一片茂密的森林，树木高大，颜色深绿。远处是连绵的雪山，山顶覆盖着白雪，山体雄伟壮观。天空湛蓝，几缕白云点缀其间，整个场景给人一种宁静、自然的感觉。\n\n右侧的图片是一张信息图，背景为白色。图中展示了四个蓝色的矩形框，每个框内都有文字内容，分别是：\n\n1. **精选模型**：\n   - 多行业各业务场景模型支持\n   - 精选多家优质大模型\n   - 丰富的平台应用与工具\n   - 搭建专属您的创新场景\n   - 客户拥有更多选择\n\n2. **数据安全**：\n   - 安全可信方案\n   - 保障模型供应商模型安全\n   - 保障客户企业数据安全\n   - 保障多方知识产权\n\n3. **强劲算力**：\n   - 算力充足且功能完备\n   - 基于火山的万卡资源池\n   - 基于高性能的训练、推理资源\n   - 包含模型精调、测评、推理等功能\n\n4. **企业级服务**：\n   - 专业服务体系支持和团队\n   - 专业的产品与运营团队\n   - 专业的销售与交付团队\n   - 满足企业的应用与交付需求\n\n这些内容可能是在介绍某个企业或平台的服务优势，包括模型选择、数据安全、计算能力和企业级服务等方面。",
                "role": "assistant"
            }
        }
    ],
    "created": 1730896926,
    "id": "021730896918756a0f9b9ad2029****",
    "model": "doubao-1.5-vision-pro-32k-250115",
    "service_tier": "default",
    "service_tier": "default",
    "object": "chat.completion",
    "usage": {
        "completion_tokens": 601,
        "prompt_tokens": 989,
        "total_tokens": 1590,
        "prompt_tokens_details": {
            "cached_tokens": 0
        }
    }
}

错误处理

错误响应
本接口调用失败的返回结构和参数释义请参见返回结构文档。

错误码
本接口与业务逻辑相关的错误码如下表所示。公共错误码请参见公共错误码。

在方舟控制台接入点配置页面或者 CreateEndpoint 接口中，将内容护栏方案（ModerationStrategy）设置为默认方案（Default）时：
HTTP 状态码

错误类型 type

错误代码 code

错误信息 message

含义

400

BadRequest

SensitiveContentDetected

The request failed because the input text may contain sensitive information.

输入文本可能包含敏感信息，请您使用其他 prompt

在方舟控制台接入点配置页面或者 CreateEndpoint 接口中，将内容护栏方案（ModerationStrategy）设置为基础方案（Basic）时：
HTTP 状态码

错误类型 type

错误代码 code

错误信息 message

含义

400

BadRequest

SensitiveContentDetected.SevereViolation

The request failed because the input text may contain severe violation information.

输入文本可能包含严重违规相关信息，请您使用其他 prompt

400

BadRequest

SensitiveContentDetected.Violence

The request failed because the input text may contain violence information.

输入文本可能包含激进行为相关信息，请您使用其他 prompt